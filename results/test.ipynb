{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bafb006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies\n",
    "import pandas as pd\n",
    "from ExtractionPipeline import extraction_pipeline\n",
    "import tomllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aafa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/01_251021_AvisFiscalite.csv\")\n",
    "col_name = \"QUXVlc3Rpb246MTYz - Que faudrait-il faire pour rendre la fiscalité plus juste et plus efficace ?\"\n",
    "df = df[['authorId', col_name]].rename({\"authorId\": \"author_id\", col_name:'contribution'}, axis=1)\n",
    "df = df.iloc[:100]  # Limitation à 100 lignes pour les tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281cda6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"01_251021_Prompt.toml\", \"rb\") as f:\n",
    "    toml_data = tomllib.load(f)\n",
    "\n",
    "system_prompt = toml_data[\"prompt\"][\"system\"]\n",
    "user_template = toml_data[\"prompt\"][\"user\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_results = extraction_pipeline(\n",
    "    df, \n",
    "    extract_model=\"gemma3:1b\",\n",
    "    system_prompt=system_prompt,\n",
    "    user_template=user_template,\n",
    "    return_sentiments=True,\n",
    "    return_complet=True,\n",
    "    error_filter=False,\n",
    "    qualit_filter=0.0,\n",
    "    rouge1_filter=0.0,\n",
    "    rougeL_filter=0.0,\n",
    "    nli_filter=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf738ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Calcul du score NLI\n",
    "    device_t = torch.device(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(nli_model, use_fast=False)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(nli_model).to(device_t)\n",
    "    model.eval()\n",
    "    cfg = AutoConfig.from_pretrained(nli_model)\n",
    "    id2label = {int(k): v for k, v in cfg.id2label.items()} if isinstance(cfg.id2label, dict) else cfg.id2label\n",
    "    entail_idx = next((k for k, v in id2label.items() if \"entail\" in str(v).lower()), 2)\n",
    "    contra_idx = next((k for k, v in id2label.items() if \"contrad\" in str(v).lower()), 0)\n",
    "    n = len(data_extracted)\n",
    "    entail = np.zeros(n, dtype=np.float32)\n",
    "    contra = np.zeros(n, dtype=np.float32)\n",
    "    with torch.inference_mode():\n",
    "        for start in range(0, n, 1):\n",
    "            end = min(start + 1, n)\n",
    "            premises = data_extracted[\"contribution\"].iloc[start:end].fillna(\"\").astype(str).tolist()\n",
    "            hypos = data_extracted[\"extraction\"].iloc[start:end].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "            enc = tokenizer(\n",
    "                premises,\n",
    "                hypos,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            enc = {k: v.to(device_t) for k, v in enc.items()}\n",
    "            probs = torch.softmax(model(**enc).logits, dim=1).detach().cpu().numpy()\n",
    "            entail[start:end] = probs[:, entail_idx]\n",
    "            contra[start:end] = probs[:, contra_idx]\n",
    "    data_extracted[\"nli_entailment\"] = entail.astype(float)\n",
    "    data_extracted[\"nli_contradiction\"] = contra.astype(float)\n",
    "    data_extracted[\"nli_score\"] = (1.0 - data_extracted[\"nli_contradiction\"]).astype(float)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythenv (3.13.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
